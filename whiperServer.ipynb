{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "modelWhisper = whisper.load_model('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Servidor Multihilo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from threading import Lock\n",
    "\n",
    "import time\n",
    "# Asegúrate de importar tu modelo Whisper correctamente\n",
    "# from tu_paquete import modelWhisper\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Crea un bloqueo para proteger el código contra la concurrencia\n",
    "transcribe_lock = Lock()\n",
    "\n",
    "@app.route('/transcribe', methods=['POST'])\n",
    "def transcribe_audio():\n",
    "    # Comprueba si el archivo fue enviado\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify(error=\"No file part\"), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "\n",
    "    # Comprueba si el usuario no seleccionó un archivo\n",
    "    if file.filename == '':\n",
    "        return jsonify(error=\"No selected file\"), 400\n",
    "\n",
    "    # Genera un nombre de archivo único utilizando una marca de tiempo\n",
    "    timestamp = int(time.time() * 1000)  # Marca de tiempo en milisegundos\n",
    "    mp3_filepath = f\"received_audio_{timestamp}.mp3\"\n",
    "    file.save(mp3_filepath)\n",
    "\n",
    "    # Transcribe el archivo MP3 (Asegúrate de tener el modelo cargado correctamente)\n",
    "    # Transcribe el archivo MP3 dentro de una sección crítica protegida por un bloqueo\n",
    "    with transcribe_lock:    \n",
    "        transcripcion = modelWhisper.transcribe(mp3_filepath, fp16=False)\n",
    "\n",
    "    # Aquí estoy comentando la transcripción real y devolviendo una cadena de marcador de posición\n",
    "    # Una vez que tengas tu modelo Whisper configurado correctamente, descomenta la línea de transcripción anterior\n",
    "    # transcripcion = \"Transcripción de ejemplo\"\n",
    "\n",
    "    # # Devuelve la transcripción\n",
    "    return jsonify(transcripcion=transcripcion)\n",
    "    # Devuelve la transcripción\n",
    "    # return jsonify(transcripcion={\"text\": transcripcion})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5500, threaded=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import threading\n",
    "\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "from pydub import AudioSegment, silence\n",
    "\n",
    "\n",
    "from pydub import AudioSegment, silence\n",
    "\n",
    "def quitar_silencios(input_filepath, output_filepath, min_silence_len=1000, new_silence_len=500, silence_thresh=-50):\n",
    "    \"\"\"\n",
    "    Elimina silencios largos de un archivo de audio.\n",
    "\n",
    "    Parámetros:\n",
    "    - input_filepath: ruta al archivo de audio de entrada (MP3).\n",
    "    - output_filepath: ruta al archivo de audio de salida (MP3).\n",
    "    - min_silence_len: duración mínima del silencio a eliminar (en milisegundos).\n",
    "    - new_silence_len: duración de los nuevos segmentos de silencio (en milisegundos).\n",
    "    - silence_thresh: umbral de silencio (en dB).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cargar el archivo de audio\n",
    "    audio_segment = AudioSegment.from_mp3(input_filepath)\n",
    "    \n",
    "    # Encuentra los segmentos de audio separados por silencios\n",
    "    segments = silence.split_on_silence(audio_segment, min_silence_len=min_silence_len, silence_thresh=silence_thresh)\n",
    "\n",
    "    # Crear un nuevo segmento de audio con silencios ajustados\n",
    "    new_audio_segment = AudioSegment.empty()\n",
    "    silence_chunk = AudioSegment.silent(duration=new_silence_len)  # Chunk de silencio de la nueva duración\n",
    "\n",
    "    # Añade cada segmento de audio al nuevo audio, intercalando con los nuevos segmentos de silencio\n",
    "    for segment in segments:\n",
    "        new_audio_segment += segment + silence_chunk\n",
    "\n",
    "    # Removemos el último chunk de silencio añadido\n",
    "    new_audio_segment = new_audio_segment[:-new_silence_len]\n",
    "\n",
    "    # Guarda el nuevo archivo de audio\n",
    "    new_audio_segment.export(output_filepath, format=\"mp3\")\n",
    "\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def es_silencioso(filepath, silence_thresh=-55):\n",
    "    \"\"\"\n",
    "    Detecta si un archivo de audio es completamente silencioso.\n",
    "\n",
    "    Parámetros:\n",
    "    - filepath: ruta al archivo de audio (MP3).\n",
    "    - silence_thresh: umbral de silencio (en dB).\n",
    "\n",
    "    Retorna:\n",
    "    - True si el archivo es silencioso, False en caso contrario.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cargar el archivo de audio\n",
    "    audio_segment = AudioSegment.from_mp3(filepath)\n",
    "    \n",
    "    # Obtener el nivel de dB del archivo\n",
    "    db_level = audio_segment.dBFS\n",
    "\n",
    "    # Comprobar si el nivel de dB está por debajo del umbral de silencio\n",
    "    return db_level < silence_thresh\n",
    "\n",
    "\n",
    "\n",
    "# Inicializa el reconocedor de voz\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "def send_audio_to_server(mp3_file, wav_file):\n",
    "    # Convierte el archivo WAV a MP3\n",
    "    AudioSegment.from_wav(wav_file).export(mp3_file, format=\"mp3\")\n",
    "\n",
    "    mp3_file_sin_silencios = f\"{mp3_file}_sin_silencios.mp3\"\n",
    "    # quitar silencios\n",
    "    quitar_silencios(mp3_file, mp3_file_sin_silencios)\n",
    "    \n",
    "    # Envía el archivo MP3 a un servidor\n",
    "    url = \"http://ia.javiergimenez.es:5500/transcribe\"\n",
    "    \n",
    "    if not es_silencioso(mp3_file):\n",
    "        with open(mp3_file_sin_silencios, 'rb') as f:\n",
    "            response = requests.post(url, files={'file': f})\n",
    "\n",
    "        # Muestra la respuesta del servidor\n",
    "        response_data = response.json()  # Deserializa la respuesta JSON a un diccionario\n",
    "        transcripcion = response_data.get(\"transcripcion\", {}).get(\"text\", \"No se pudo obtener la transcripción\")\n",
    "        print(\"Respuesta del servidor:\", transcripcion)\n",
    "\n",
    "    else:\n",
    "        print(\"Archivo silencioso, no se envía al servidor\")\n",
    "\n",
    "while True:\n",
    "    # Captura el audio del micrófono\n",
    "    with sr.Microphone() as source:      \n",
    "        print(\"Capturando audio...\")\n",
    "        audio_data = recognizer.listen(source)\n",
    "        print(\"Captura completa.\")\n",
    "\n",
    "    # Guarda el audio capturado como un archivo WAV\n",
    "    wav_file = f\"captured_audio_{iteration % 2}.wav\"\n",
    "    with open(wav_file, \"wb\") as f:\n",
    "        f.write(audio_data.get_wav_data())\n",
    "\n",
    "    # Define el nombre del archivo MP3\n",
    "    mp3_file = f\"captured_audio_{iteration % 2}.mp3\"\n",
    "\n",
    "    # Inicia un nuevo hilo para convertir y enviar el archivo MP3 al servidor\n",
    "    threading.Thread(target=send_audio_to_server, args=(mp3_file, wav_file)).start()\n",
    "\n",
    "    # Incrementa el contador de iteraciones\n",
    "    iteration += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Servidor bloqueante (inicial que hice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "# Asegúrate de importar tu modelo Whisper correctamente\n",
    "# from tu_paquete import modelWhisper\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/transcribe', methods=['POST'])\n",
    "def transcribe_audio():\n",
    "    # Comprueba si el archivo fue enviado\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify(error=\"No file part\"), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "\n",
    "    # Comprueba si el usuario no seleccionó un archivo\n",
    "    if file.filename == '':\n",
    "        return jsonify(error=\"No selected file\"), 400\n",
    "\n",
    "    # Guarda el archivo en el servidor\n",
    "    mp3_filepath = \"received_audio.mp3\"\n",
    "    file.save(mp3_filepath)\n",
    "\n",
    "    # Transcribe el archivo MP3 (Asegúrate de tener el modelo cargado correctamente)\n",
    "    transcripcion = modelWhisper.transcribe(mp3_filepath)\n",
    "\n",
    "    # Aquí estoy comentando la transcripción real y devolviendo una cadena de marcador de posición\n",
    "    # Una vez que tengas tu modelo Whisper configurado correctamente, descomenta la línea de transcripción anterior\n",
    "    # transcripcion = \"Transcripción de ejemplo\"\n",
    "\n",
    "    # Devuelve la transcripción\n",
    "    return jsonify(transcripcion=transcripcion)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5500)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
